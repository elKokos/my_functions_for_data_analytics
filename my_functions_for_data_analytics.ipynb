{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26114b17",
   "metadata": {},
   "source": [
    "<b>don't forget! üëá</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bb7bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T19:22:16.939449Z",
     "start_time": "2023-12-05T19:22:16.928715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3c57c",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fff30cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T19:07:49.858432Z",
     "start_time": "2023-12-05T19:07:49.640912Z"
    }
   },
   "outputs": [],
   "source": [
    "#must have\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats and tests\n",
    "from scipy import stats as st\n",
    "\n",
    "# visualisation\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# hash\n",
    "import hashlib\n",
    "# it's booster for apply\n",
    "import swifter\n",
    "\n",
    "# additional\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import ipywidgets\n",
    "\n",
    "# working with json format\n",
    "import json\n",
    "\n",
    "# map, choropleth and marker\n",
    "from folium import Map, Choropleth, Marker\n",
    "# clusters\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f77b5",
   "metadata": {},
   "source": [
    "#### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞ (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ef219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≤—ã–≤–æ–¥ –≤—Å–µ—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "pd.set_option('display.max_columns', None)\n",
    "# –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —è—á–µ–π–∫–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–Ω–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# –≤–æ–ª—à–µ–±–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—à–∏–±–æ–∫\n",
    "%xmode Verbose\n",
    "# –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ —è—á–µ–π–∫–∞—Ö –±–ª–æ–∫–Ω–æ—Ç–∞\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d121045",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a1a25",
   "metadata": {},
   "source": [
    "##### describe_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(data):\n",
    "    \"\"\"\n",
    "     –í—ã–≤–æ–¥–∏—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ DataFrame, –≤–∫–ª—é—á–∞—è:\n",
    "    - 10 —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã\n",
    "    - —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å DataFrame\n",
    "    - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —á–∏—Å–ª–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–∞–º\n",
    "    - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–∞–º\n",
    "    - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü–µ\n",
    "    - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ\n",
    "    - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫\n",
    "    - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ\n",
    "    \"\"\"\n",
    "    # –≤—ã–≤–æ–¥ 10 —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç—Ä–æ–∫\n",
    "    print('\\033[92m–≤—ã–≤–æ–¥ —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã:\\033[90m\\n')\n",
    "    # –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ –º–µ–Ω—å—à–µ 10, —Ç–æ –≤—ã—Å–∫–æ—á–∏—Ç –æ—à–∏–±–∫–∞\n",
    "    # –æ—Ç–ª–∞–≤–ª–∏–≤–∞–µ–º –µ–µ –∏ –≤—ã–≤–æ–¥–∏–º –≤—Å–µ –∏–º–µ—é—â–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü–µ\n",
    "    try:\n",
    "        display(data.sample(10))\n",
    "    except:\n",
    "        display(data.sample(data.shape[0]))\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö\n",
    "    print('–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:')\n",
    "    print(data.dtypes)\n",
    "    ('-----------------------------------------------------------------------')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫\n",
    "    print('\\033[92m–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫:\\033[90m',\n",
    "          f'\\033[91m{data.shape[0]}\\033[90m')\n",
    "    print('-----------------------------------------------------------------------')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "    print('\\033[92m–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤:\\033[90m',\n",
    "          f'\\033[91m{data.shape[1]}\\033[90m')\n",
    "    print('-----------------------------------------------------------------------')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–∞—Ö\n",
    "    print('\\033[92m–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —á–∏—Å–ª–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–∞–º:\\033[90m\\n')\n",
    "    for column in data.select_dtypes(include='number'):\n",
    "        print(data[column].describe(), '\\n')\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ—ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    print('\\033[92m–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–∞–º:\\033[90m\\n')\n",
    "    for column in data.select_dtypes(include='object'):\n",
    "        print(data[column].describe(), '\\n')\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ —Å—Ç–æ–ª–±—Ü–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –ø—Ä–æ–ø—É—Å–∫–∏, –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ\n",
    "    print('\\033[92m–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü–µ:\\033[90m\\n')\n",
    "    # —ç—Ç–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω—É–∂–Ω–æ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Å—Ç–æ–ª–±–∏–∫–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏\n",
    "    count_na = 0\n",
    "    for column in data.columns:\n",
    "        null_in_column = data[column].isna().sum()\n",
    "\n",
    "        if null_in_column:\n",
    "            count_na += 1\n",
    "            print(f'\\033[91m{column}: {null_in_column}\\033[90m')\n",
    "            print(\n",
    "                '-----------------------------------------------------------------------')\n",
    "    if count_na == 0:\n",
    "        print('–í —Ç–∞–±–ª–∏—Ü–µ –Ω–µ—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤ ü•Ç')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö –∫–∞–∂–¥–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞\n",
    "    print('\\033[92m–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ:\\033[90m\\n')\n",
    "    for column in data.columns:\n",
    "        unique_values = data[column].nunique()\n",
    "        print(f'{column} : {unique_values}')\n",
    "        print('-----------------------------------------------------------------------')\n",
    "\n",
    "    # –≤—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö\n",
    "    print('\\n')\n",
    "    duplicated_value = data.duplicated().sum()\n",
    "    if duplicated_value:\n",
    "        print(\n",
    "            f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫: \\033[91m{duplicated_value}\\033[90m')\n",
    "    else:\n",
    "        print('\\033[94m–î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Ç—Ä–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ\\033[90m')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d7be3",
   "metadata": {},
   "source": [
    "##### create_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2261b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_missing_df(data):\n",
    "    \"\"\"\n",
    "    —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –Ω–∞–º —Ç–∞–±–ª–∏—Ü—É —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –≤–µ—Ä–Ω–µ—Ç –µ–µ\n",
    "    –Ω–∞ –≤—Ö–æ–¥ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä - DataFrame\n",
    "    \"\"\"\n",
    "    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –¥—Ñ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö\n",
    "    # —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã\n",
    "    missing_df = data.isna().sum(axis=0).reset_index()\n",
    "\n",
    "    # –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º –∫–æ–ª–æ–Ω–∫–∏\n",
    "    missing_df.columns = ['column_name', 'missing_count']\n",
    "\n",
    "    # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏—Å—Ç—É—Å—Ç–≤—É—é—Ç –ø—Ä–æ–ø—É—Å–∫–∏ + —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞\n",
    "    missing_df = missing_df[missing_df['missing_count'] > 0]\n",
    "    missing_df = missing_df.sort_values('missing_count', ascending=True)\n",
    "\n",
    "    # —Å—á–∏—Ç–∞–µ–º % –ø—Ä–æ–ø—É—Å–∫–æ–≤ –æ—Ç –æ–±—â–µ–≥–æ\n",
    "    missing_df['%'] = np.round((missing_df['missing_count'] / data.shape[0])*100, 2)\n",
    "\n",
    "    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥—Ñ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–∞–∂–¥–æ–º —Å—Ç–æ–ª–±—Ü–µ\n",
    "    return missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e1600",
   "metadata": {},
   "source": [
    "##### remove_outliners_IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a76731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliners_IQR(data, column_name):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ –∏–∑ DataFrame,\n",
    "    —Å–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –¥–æ –∏ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤,\n",
    "    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame –∏ DataFrame —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    - data: –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "    - column_name: –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "    \"\"\"\n",
    "    # —Å–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é —Ç–∞–±–ª–∏—Ü—ã\n",
    "    data_after_remove = data.copy()\n",
    "    # –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å—Ç–æ–ª–±—Ü–∞ (–∫–≤–∞—Ä—Ç–∏–ª–∏)\n",
    "    Q1 = data_after_remove[column_name].quantile(0.25)\n",
    "    Q3 = data_after_remove[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    # –≤—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –º–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # —É–¥–∞–ª—è–µ–º –≤—ã–±—Ä–æ—Å—ã –∏–∑ —Å—Ç–æ–ª–±—Ü–∞\n",
    "    # –∑–∞–ø–∏—à–µ–º —É–¥–∞–ª–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ—á–∫–∏ –≤ –Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "    removed_df = data_after_remove[(data_after_remove[column_name] < lower_bound) |\n",
    "                                   (data_after_remove[column_name] > upper_bound)].copy()\n",
    "\n",
    "    # –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "    data_after_remove = data_after_remove[(data_after_remove[column_name] >= lower_bound) &\n",
    "                                          (data_after_remove[column_name] <= upper_bound)]\n",
    "\n",
    "    # –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –¥–æ –∏ –ø–æ—Å–ª–µ\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # –ø–µ—Ä–≤—ã–π –≥—Ä–∞—Ñ–∏–∫\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.boxplot(data[column_name])\n",
    "    plt.title('–î–æ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤')\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "    # –≤—Ç–æ—Ä–æ–π –≥—Ä–∞—Ñ–∏–∫\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(data_after_remove[column_name].dropna())\n",
    "    plt.title('–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤')\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –¥—Ñ –∏ –¥—Ñ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏\n",
    "    return data_after_remove, removed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541db79",
   "metadata": {},
   "source": [
    "##### create_random_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf014c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_color():\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —Ü–≤–µ—Ç \n",
    "    \"\"\"\n",
    "    r = random.random()\n",
    "    g = random.random()\n",
    "    b = random.random()\n",
    "    return (r, g, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119e236",
   "metadata": {},
   "source": [
    "##### convert_to_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052a65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –∫ –∑–º–µ–∏–Ω–æ–π –Ω–æ—Ç–∞—Ü–∏–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ —Å—Ç—Ä–æ–∫ –∏–∑ DataFrame,\n",
    "    –≤ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∑–∞–º–µ–Ω—è–µ—Ç –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –∞–Ω–¥–µ—Ä—Å–∫–æ—Ä,\n",
    "    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    - data: –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "    \"\"\"\n",
    "    def camel_to_snake(word):\n",
    "        \"\"\"\n",
    "        —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ—Ç–∞—Ü–∏–∏ camelCase –∫ snake_case\n",
    "        \"\"\"\n",
    "        \n",
    "        snake_case_string = \"\"\n",
    "        for i, c in enumerate(word):\n",
    "            if i == 0:\n",
    "                snake_case_string += c.lower()\n",
    "            elif c.isupper():\n",
    "                snake_case_string += \"_\" + c.lower()\n",
    "            else:\n",
    "                snake_case_string += c\n",
    "        return snake_case_string\n",
    "    \n",
    "    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –∑–º–µ–∏–Ω–æ–π –Ω–æ—Ç–∞—Ü–∏–∏\n",
    "    data.rename(columns=camel_to_snake, inplace=True)\n",
    "    \n",
    "    # —Ä–∞–±–æ—Ç–∞ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Å—Ç—Ä–æ—á–∫–∞—Ö —Ç–æ–ª—å–∫–æ —Å —Ç–∏–ø–æ–º –¥–∞–Ω–Ω—ã—Ö object\n",
    "    for column in data.select_dtypes(include='object'):\n",
    "        data[column] = data[column].apply(camel_to_snake)\n",
    "    \n",
    "    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64006d93",
   "metadata": {},
   "source": [
    "##### get_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70e7611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T19:11:39.844125Z",
     "start_time": "2023-12-05T19:11:39.835042Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_color(name, number):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤\n",
    "    –Ω–∞ –≤—Ö–æ–¥ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–∞—Å—Ü–≤–µ—Ç–∫—É(name) –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ü–≤–µ—Ç–æ–≤(number)\n",
    "    \n",
    "    –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –º–æ–∏—Ö –ø–∞–ª–µ—Ç–æ–∫:\n",
    "    - viridis_r\n",
    "    - plasma_r\n",
    "    - Spectral\n",
    "    - hsv\n",
    "    \"\"\"\n",
    "    \n",
    "    pal = list(sns.color_palette(palette=name, n_colors=number).as_hex())\n",
    "\n",
    "    return pal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec2119",
   "metadata": {},
   "source": [
    "##### ab_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4590027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_split(id, salt='exp_mess_1', n_groups=5):\n",
    "    \"\"\"\n",
    "    —Ñ—É–Ω–∫—Ü–∏—è —Ä–µ–∞–ª–∏–∑—É—é—â–∞—è —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞ n –≥—Ä—É–ø–ø\n",
    "    \"\"\"\n",
    "    test_id = str(id) + '-' + str(salt)\n",
    "    test_id_digest = hashlib.md5(test_id.encode('ascii')).hexdigest()\n",
    "    test_id_final_int = int(test_id_digest, 16)\n",
    "\n",
    "    return test_id_final_int % n_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8d259",
   "metadata": {},
   "source": [
    "##### prioritize_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48cc53",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prioritize_hypotheses(data, method='ice'):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è, –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É—é—â–∞—è –≥–∏–ø–æ—Ç–µ–∑—ã –º–µ—Ç–æ–¥–æ–º ICE –∏–ª–∏ RICE,\n",
    "    —Å–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞) \n",
    "    –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ —É–±—ã–≤–∞–Ω–∏—é DataFrame –ø–æ —Ä–∞–Ω–≥—É –Ω–∞–±—Ä–∞–Ω–Ω—ã—Ö –±–∞–ª–ª–æ–≤.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame.\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    - data: –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ;\n",
    "    - method: –º–µ—Ç–æ–¥ –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π—Å—è –¥–ª—è –ø—Ä–∏–æ—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–æ—Ç–µ–∑ (–ø–æ-—É–º–æ–ª—á–∞–Ω–∏—é ICE).\n",
    "    \n",
    "    -------\n",
    "    –í–ê–ñ–ù–û!!! DataFrame –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –∞ –∏–º–µ–Ω–Ω–æ:\n",
    "    - impact (–≤–ª–∏—è–Ω–∏–µ);\n",
    "    - confidence (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å);\n",
    "    - efforts (—É—Å–∏–ª–∏—è);\n",
    "    - reach (–æ—Ö–≤–∞—Ç).\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'ice':\n",
    "        # —Å—á–∏—Ç–∞–µ–º –∏ –æ–∫—Ä—É–≥–ª—è–µ–º –¥–æ 3 —Ü–∏—Ñ—Ä –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π\n",
    "        data['ice_score'] = ((data.impact * data.confidence) / data.efforts).round(3)\n",
    "        \n",
    "        # —Ä–∞–Ω–∂–∏—Ä—É–µ–º –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ + –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–Ω–∫ –≤ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ\n",
    "        data['ice_rank'] = data['ice_score'].rank(ascending=False).astype(int)\n",
    "        \n",
    "        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –ø–æ —Ä–∞–Ω–≥—É\n",
    "        return data.sort_values(by='ice_rank')\n",
    "    \n",
    "    elif method == 'rice':\n",
    "        # —Å—á–∏—Ç–∞–µ–º –∏ –æ–∫—Ä—É–≥–ª—è–µ–º –¥–æ 3 —Ü–∏—Ñ—Ä –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π\n",
    "        data['rice_score'] = (data.reach * data.impact * data.confidence) / data.efforts\n",
    "        \n",
    "        # —Ä–∞–Ω–∂–∏—Ä—É–µ–º –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ + –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–Ω–∫ –≤ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ\n",
    "        data['rice_rank'] = data['rice_score'].rank(ascending=False).astype(int)\n",
    "        \n",
    "        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π DataFrame —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –ø–æ —Ä–∞–Ω–≥—É\n",
    "        return data.sort_values(by='rice_rank')\n",
    "    else:\n",
    "        print('–û—à–∏–±–∫–∞! –Ω–µ—Ç —Ç–∞–∫–æ–≥–æ –º–µ—Ç–æ–¥–∞')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693c08c",
   "metadata": {},
   "source": [
    "##### get_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e6393-9606-42b4-83a2-d7cad3128b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profiles(sessions, \n",
    "                 orders,  \n",
    "                 ad_costs\n",
    "                ):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã —Å –ø—Ä–æ—Ñ–∏–ª–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤. –û–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    orders: –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –∑–∞–∫–∞–∑–∞–º–∏.\n",
    "    ad_costs: –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –∑–∞—Ç—Ä–∞—Ç–∞–º–∏ –Ω–∞ —Ä–µ–∫–ª–∞–º—É.\n",
    "    \"\"\"\n",
    "\n",
    "    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ—Å—Å–∏–∏ –ø–æ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –¥–∞—Ç–µ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è\n",
    "    # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ ID –∏ –Ω–∞—Ö–æ–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–≤—ã—Ö –ø–æ—Å–µ—â–µ–Ω–∏–π\n",
    "    profiles = (\n",
    "        sessions.sort_values(by=['user_id', 'session_start'])\n",
    "        .groupby('user_id')\n",
    "        .agg(\n",
    "            {\n",
    "                'session_start': 'first',\n",
    "                'channel': 'first',\n",
    "                'device': 'first',\n",
    "                'region': 'first',\n",
    "            }\n",
    "        )\n",
    "         # –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ –ø–æ—Å–µ—â–µ–Ω–∏—è –Ω–∞–∑–æ–≤—ë–º first_ts\n",
    "        .rename(columns={'session_start': 'first_ts'})\n",
    "        .reset_index()  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º user_id –∏–∑ –∏–Ω–¥–µ–∫—Å–∞\n",
    "    )\n",
    "\n",
    "    # –¥–ª—è –∫–æ–≥–æ—Ä—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—É –ø–µ—Ä–≤–æ–≥–æ –ø–æ—Å–µ—â–µ–Ω–∏—è\n",
    "    # –∏ –ø–µ—Ä–≤—ã–π –¥–µ–Ω—å –º–µ—Å—è—Ü–∞, –≤ –∫–æ—Ç–æ—Ä—ã–π —ç—Ç–æ –ø–æ—Å–µ—â–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ\n",
    "    profiles['dt'] = profiles['first_ts'].dt.date\n",
    "    profiles['month'] = profiles['first_ts'].astype('datetime64[M]')\n",
    "\n",
    "    # –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫ –ø–ª–∞—Ç—è—â–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    profiles['payer'] = profiles['user_id'].isin(orders['user_id'].unique())\n",
    "\n",
    "\n",
    "    # —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    # —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –∏ –¥–∞—Ç–æ–π –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è\n",
    "    new_users = (\n",
    "        profiles.groupby(['dt', 'channel'])\n",
    "        .agg({'user_id': 'nunique'})\n",
    "         # —Å—Ç–æ–ª–±–µ—Ü —Å —á–∏—Å–ª–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞–∑–æ–≤—ë–º unique_users\n",
    "        .rename(columns={'user_id': 'unique_users'})\n",
    "        .reset_index()  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º dt –∏ channel –∏–∑ –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "    )\n",
    "\n",
    "    # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ç—Ä–∞—Ç—ã –Ω–∞ —Ä–µ–∫–ª–∞–º—É –∏ —á–∏—Å–ª–æ –ø—Ä–∏–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    # –ø–æ –¥–∞—Ç–µ –∏ –∫–∞–Ω–∞–ª—É –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è\n",
    "    ad_costs = ad_costs.merge(new_users, on=['dt', 'channel'], how='left')\n",
    "\n",
    "    # –¥–µ–ª–∏–º —Ä–µ–∫–ª–∞–º–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã –Ω–∞ —á–∏—Å–ª–æ –ø—Ä–∏–≤–ª–µ—á—ë–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    # —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–∏–º –≤ —Å—Ç–æ–ª–±–µ—Ü acquisition_cost (CAC)\n",
    "    ad_costs['acquisition_cost'] = ad_costs['costs'] / ad_costs['unique_users']\n",
    "\n",
    "    # –¥–æ–±–∞–≤–∏–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –≤ –ø—Ä–æ—Ñ–∏–ª–∏\n",
    "    profiles = profiles.merge(\n",
    "        ad_costs[['dt', 'channel', 'acquisition_cost']],\n",
    "        on=['dt', 'channel'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ —Å–≤—è–∑–∞–Ω—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ä–µ–∫–ª–∞–º–µ,\n",
    "    # –ø–æ—ç—Ç–æ–º—É –≤ —Å—Ç–æ–ª–±—Ü–µ acquisition_cost —É –Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è NaN\n",
    "    # –∑–∞–º–µ–Ω–∏–º –∏—Ö –Ω–∞ –Ω–æ–ª—å, –≤–µ–¥—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è —Ä–∞–≤–Ω–∞ –Ω—É–ª—é\n",
    "    profiles['acquisition_cost'] = profiles['acquisition_cost'].fillna(0)\n",
    "    \n",
    "    return profiles  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ —Å CAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762f7dd",
   "metadata": {},
   "source": [
    "##### get_retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e57de5-06a4-4603-ab63-984e0196db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retention(profiles, \n",
    "                  sessions, \n",
    "                  observation_date, \n",
    "                  horizon_days, \n",
    "                  dimensions = [], \n",
    "                  ignore_horizon = False\n",
    "                 ):\n",
    "    \n",
    "    # —Ä–µ—à–∞–µ–º –∫–∞–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã –æ—Å—Ç–∞–≤–∏–º –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è, —Å—Ç–æ–ª–±–µ—Ü –ø—Ä–∏–∑–Ω–∞–∫–∞ –ø–ª–∞—Ç—è—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Å—Ç–∞–µ—Ç—Å—è –≤—Å–µ–≥–¥–∞\n",
    "    dimensions = ['payer'] + dimensions\n",
    "    \n",
    "    # –æ—Ç—Ç—Å–µ–∫–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –º–æ–≥–ª–∏ \"–¥–æ–∂–∏—Ç—å\" –¥–æ –Ω—É–∂–Ω–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ \n",
    "    # (–ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏–ª–∏—Å—å –ø–æ–∑–∂–µ —á–µ–º observation_date - horizon)\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(days = horizon_days - 1)\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "\n",
    "    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –º–∞—Å—Å–∏–≤ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    result_raw = result_raw.merge(sessions[['user_id', 'session_start']], on = 'user_id', how = 'left')\n",
    "    result_raw['lifetime'] = (result_raw['session_start'] - result_raw['first_ts']).dt.days\n",
    "    \n",
    "    # —Ñ—É–Ω–∫—Ü–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –Ω—É–∂–Ω–æ–º—É –Ω–∞–±–æ—Ä—É –∏–∑–º–µ—Ä–µ–Ω–∏–π\n",
    "    def group_by_dimensions(df, dims, horizon_days):     \n",
    "        result = df.pivot_table(index = dims, columns = 'lifetime', values = 'user_id', aggfunc = 'nunique')     # —Å—Ç—Ä–æ–∏–º \"—Ç—Ä–µ—É–≥–æ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É\" \n",
    "        cohort_sizes = df.groupby(dims).agg({'user_id': 'nunique'}).rename(columns = {'user_id': 'cohort_size'}) # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç\n",
    "        result = cohort_sizes.merge(result, on = dims, how = 'left').fillna(0)                                   # –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç –∫ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ\n",
    "        result = result.div(result['cohort_size'], axis = 0)                                                     # –¥–µ–ª–∏–º –∫–∞–∂–¥—ã–π –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤ –Ω–∞ —Ä–∞–∑–º–µ—Ä –∫–æ–≥–æ—Ä—Ç—ã - —Ä–∞—Å—á–∏—Ç—ã–≤–∞–µ–º % —É–¥–µ—Ä–∂–∞–Ω–∏—è (retention rate)\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]                                             # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è –¥–æ –Ω—É–∂–Ω–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –∏ —Å—Ç–æ–ª–±–µ—Ü —Ä–∞–∑–º–µ—Ä–æ–≤ –∫–æ–≥–æ—Ä—Ç\n",
    "        result['cohort_size'] = cohort_sizes                                                                     # –ø–µ—Ä–µ—Å–ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü —Ä–∞–∑–º–µ—Ä–æ–≤ –∫–æ–≥–æ—Ä—Ç, –≤–µ–¥—å –≤–æ –≤—Ä–µ–º—è –¥–µ–ª–µ–Ω–∏—è –æ–Ω –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª—Å—è –≤ 1\n",
    "        return result\n",
    "    \n",
    "    # —Ä–∞—Å—á–∏—Ç—ã–≤–∞–µ–º —É–¥–µ—Ä–∂–∞–Ω–∏–µ \n",
    "    result_grouped = group_by_dimensions(result_raw, dimensions, horizon_days)\n",
    "    \n",
    "    # —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º + –¥–∞—Ç–∞\n",
    "    result_in_time = group_by_dimensions(result_raw, dimensions + ['dt'], horizon_days)\n",
    "    \n",
    "    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏ —Ç–∞–±–ª–∏—Ü—ã —É–¥–µ—Ä–∂–∞–Ω–∏—è –∏ —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—á—Ç–æ–±—ã –≤ —Å–ª—É—á–∞–µ —á–µ–≥–æ –º–æ–∂–Ω–æ –±—ã–ª–æ –≤ –Ω–∏—Ö –ø–æ–∫–æ–ø–∞—Ç—å—Å—è –ø—Ä–∏ –æ—Ç–ª–∞–¥–∫–µ)\n",
    "    return result_raw, result_grouped, result_in_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5635a8",
   "metadata": {},
   "source": [
    "##### get_ltv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0d71e-1916-48f2-8967-0cca79ebd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ltv(profiles, \n",
    "            purchases,\n",
    "            observation_date, \n",
    "            horizon_days,\n",
    "            dimensions=[], \n",
    "            ignore_horizon=False,\n",
    "           ):\n",
    "    \n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø–æ–∂–∏–∑–Ω–µ–Ω–Ω–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏ (LTV) –∫–ª–∏–µ–Ω—Ç–æ–≤. –û–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    profiles: –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ—Ñ–∏–ª—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n",
    "    purchases: –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–∫—É–ø–∫–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n",
    "    observation_date: –¥–∞—Ç–∞, –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –Ω–∞ –∫–æ—Ç–æ—Ä—É—é —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è LTV.\n",
    "    horizon_days: –≥–æ—Ä–∏–∑–æ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ –¥–Ω—è—Ö.\n",
    "    dimensions: —Å–ø–∏—Å–æ–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –±—É–¥–µ—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å—Å—è LTV.\n",
    "    ignore_horizon: —Ñ–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, —É—á–∏—Ç—ã–≤–∞—Ç—å –ª–∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ LTV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # –∏—Å–∫–ª—é—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –Ω–µ ¬´–¥–æ–∂–∏–≤—à–∏—Ö¬ª –¥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞\n",
    "    # –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –¥–∞—Ç—É –Ω–∞–±–ª—é–¥–µ–Ω–∏—è observation_date, –∫–æ—Ç–æ—Ä–∞—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω–µ—Ü –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞. \n",
    "    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–≤–µ—Ä—à–∏–ª –ø–µ—Ä–≤—É—é –ø–æ–∫—É–ø–∫—É –ø–æ—Å–ª–µ observation_date, –º—ã —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –µ–≥–æ LTV —Ä–∞–≤–µ–Ω –Ω—É–ª—é.\n",
    "    last_suitable_acquisition_date = observation_date\n",
    "    if not ignore_horizon:\n",
    "        last_suitable_acquisition_date = observation_date - timedelta(\n",
    "            days=horizon_days - 1\n",
    "        )\n",
    "    # –§—É–Ω–∫—Ü–∏—è query() –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ profiles \n",
    "    # –ø–æ —É—Å–ª–æ–≤–∏—é dt <= @last_suitable_acquisition_date, \n",
    "    # –≥–¥–µ last_suitable_acquisition_date - –¥–∞—Ç–∞, –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –Ω–∞ –∫–æ—Ç–æ—Ä—É—é —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è LTV.\n",
    "    result_raw = profiles.query('dt <= @last_suitable_acquisition_date')\n",
    "    \n",
    "    # –¥–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–∫—É–ø–∫–∞—Ö –≤ –ø—Ä–æ—Ñ–∏–ª–∏\n",
    "    # –î–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è LTV –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–Ω–∞—Ç—å, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–≤–µ—Ä—à–∏–ª –ø–µ—Ä–≤—É—é –ø–æ–∫—É–ø–∫—É –∏ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –æ–Ω –ø–æ–∫—É–ø–∞–ª –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ. \n",
    "    # –î–ª—è —ç—Ç–æ–≥–æ –º—ã –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã profiles –∏ purchases –ø–æ –ø–æ–ª—é user_id\n",
    "    result_raw = result_raw.merge(\n",
    "        purchases[['user_id', 'event_dt', 'revenue']], on='user_id', how='left'\n",
    "    )\n",
    "    \n",
    "    # —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ª–∞–π—Ñ—Ç–∞–π–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–∫—É–ø–∫–∏\n",
    "    # –õ–∞–π—Ñ—Ç–∞–π–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - —ç—Ç–æ –ø–µ—Ä–∏–æ–¥ –≤—Ä–µ–º–µ–Ω–∏ —Å –º–æ–º–µ–Ω—Ç–∞ –µ–≥–æ –ø–µ—Ä–≤–æ–π –ø–æ–∫—É–ø–∫–∏ –¥–æ –º–æ–º–µ–Ω—Ç–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π. \n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ª–∞–π—Ñ—Ç–∞–π–º –∫–∞–∫ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –¥–∞—Ç–∞–º–∏ –ø–æ–∫—É–ø–∫–∏ –∏ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
    "    result_raw['lifetime'] = (\n",
    "        result_raw['event_dt'] - result_raw['first_ts']\n",
    "    ).dt.days\n",
    "    \n",
    "    # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ cohort, –µ—Å–ª–∏ –≤ dimensions –Ω–∏—á–µ–≥–æ –Ω–µ—Ç\n",
    "    if len(dimensions) == 0:\n",
    "        result_raw['cohort'] = 'All users'\n",
    "        dimensions = dimensions + ['cohort']\n",
    "\n",
    "    # —Ñ—É–Ω–∫—Ü–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –∂–µ–ª–∞–µ–º—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "    def group_by_dimensions(df, dims, horizon_days):\n",
    "        \"\"\"\n",
    "        –§—É–Ω–∫—Ü–∏—è group_by_dimensions –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Ç–∞–±–ª–∏—Ü—É (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ result_raw)\n",
    "        horizon_days: –≥–æ—Ä–∏–∑–æ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ –¥–Ω—è—Ö.\n",
    "        dimensions: —Å–ø–∏—Å–æ–∫ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –±—É–¥–µ—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å—Å—è LTV \n",
    "        \n",
    "        –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–µ —Ç–∞–±–ª–∏—Ü—ã:\n",
    "\n",
    "        result - —Ç–∞–±–ª–∏—Ü–∞ LTV, –≤ –∫–æ—Ç–æ—Ä–æ–π –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–≥–æ—Ä—Ç–µ –∏ –ª–∞–π—Ñ—Ç–∞–π–º—É. \n",
    "        –í —è—á–µ–π–∫–∞—Ö —Ç–∞–±–ª–∏—Ü—ã —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è —Å—É–º–º–∞—Ä–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Å–æ–≤–µ—Ä—à–∏–≤—à–∏—Ö –ø–æ–∫—É–ø–∫—É –≤ —ç—Ç–æ–π –∫–æ–≥–æ—Ä—Ç–µ –∏ –∑–∞ —ç—Ç–æ—Ç –ª–∞–π—Ñ—Ç–∞–π–º.\n",
    "        \n",
    "        roi - —Ç–∞–±–ª–∏—Ü–∞ ROI, –≤ –∫–æ—Ç–æ—Ä–æ–π –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–≥–æ—Ä—Ç–µ –∏ –ª–∞–π—Ñ—Ç–∞–π–º—É. \n",
    "        –í —è—á–µ–π–∫–∞—Ö —Ç–∞–±–ª–∏—Ü—ã —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –æ—Ç–Ω–æ—à–µ–Ω–∏–µ LTV –∫ CAC.\n",
    "        \"\"\"\n",
    "        \n",
    "        # —Å—Ç—Ä–æ–∏–º ¬´—Ç—Ä–µ—É–≥–æ–ª—å–Ω—É—é¬ª —Ç–∞–±–ª–∏—Ü—É –≤—ã—Ä—É—á–∫–∏\n",
    "        result = df.pivot_table(index=dims, \n",
    "                                columns='lifetime', \n",
    "                                values='revenue', \n",
    "                                aggfunc='sum'\n",
    "                               )\n",
    "        \n",
    "        # –Ω–∞—Ö–æ–¥–∏–º —Å—É–º–º—É –≤—ã—Ä—É—á–∫–∏ —Å –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ–º\n",
    "        result = result.fillna(0).cumsum(axis=1)\n",
    "        \n",
    "        # –≤—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç\n",
    "        cohort_sizes = (\n",
    "            df.groupby(dims)\n",
    "            .agg({'user_id': 'nunique'})\n",
    "            .rename(columns={'user_id': 'cohort_size'})\n",
    "        )\n",
    "        \n",
    "        # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç –∏ —Ç–∞–±–ª–∏—Ü—É –≤—ã—Ä—É—á–∫–∏\n",
    "        result = cohort_sizes.merge(result, on=dims, how='left').fillna(0)\n",
    "        \n",
    "        # —Å—á–∏—Ç–∞–µ–º LTV: –¥–µ–ª–∏–º –∫–∞–∂–¥—É—é ¬´—è—á–µ–π–∫—É¬ª –≤ —Å—Ç—Ä–æ–∫–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä –∫–æ–≥–æ—Ä—Ç—ã\n",
    "        result = result.div(result['cohort_size'], axis=0)\n",
    "        \n",
    "        # –∏—Å–∫–ª—é—á–∞–µ–º –≤—Å–µ –ª–∞–π—Ñ—Ç–∞–π–º—ã, –ø—Ä–µ–≤—ã—à–∞—é—â–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞\n",
    "        result = result[['cohort_size'] + list(range(horizon_days))]\n",
    "        \n",
    "        # –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç\n",
    "        result['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∑–Ω–∞—á–µ–Ω–∏—è CAC, \n",
    "        # –¥–æ–±–∞–≤–∏–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ dimensions\n",
    "        cac = df[['user_id', 'acquisition_cost'] + dims].drop_duplicates()\n",
    "\n",
    "        # —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π CAC –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏–∑ dimensions\n",
    "        cac = (\n",
    "            cac.groupby(dims)\n",
    "            .agg({'acquisition_cost': 'mean'})\n",
    "            .rename(columns={'acquisition_cost': 'cac'})\n",
    "        )\n",
    "\n",
    "        # —Å—á–∏—Ç–∞–µ–º ROI: –¥–µ–ª–∏–º LTV –Ω–∞ CAC\n",
    "        roi = result.div(cac['cac'], axis=0)\n",
    "\n",
    "        # —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–º ROI\n",
    "        roi = roi[~roi['cohort_size'].isin([np.inf])]\n",
    "\n",
    "        # –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç –≤ —Ç–∞–±–ª–∏—Ü–µ ROI\n",
    "        roi['cohort_size'] = cohort_sizes\n",
    "\n",
    "        # –¥–æ–±–∞–≤–ª—è–µ–º CAC –≤ —Ç–∞–±–ª–∏—Ü—É ROI\n",
    "        roi['cac'] = cac['cac']\n",
    "\n",
    "        # –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–æ–≥–æ—Ä—Ç, CAC\n",
    "        # –∏ ROI –≤ –ª–∞–π—Ñ—Ç–∞–π–º—ã, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞\n",
    "        roi = roi[['cohort_size', 'cac'] + list(range(horizon_days))]\n",
    "\n",
    "        # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã LTV –∏ ROI\n",
    "        return result, roi\n",
    "\n",
    "    # –ø–æ–ª—É—á–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã LTV –∏ ROI\n",
    "    result_grouped, roi_grouped = group_by_dimensions(\n",
    "        result_raw, dimensions, horizon_days\n",
    "    )\n",
    "\n",
    "    # –¥–ª—è —Ç–∞–±–ª–∏—Ü –¥–∏–Ω–∞–º–∏–∫–∏ —É–±–∏—Ä–∞–µ–º 'cohort' –∏–∑ dimensions\n",
    "    if 'cohort' in dimensions:\n",
    "        dimensions = []\n",
    "    \n",
    "    # –ø–æ–ª—É—á–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –¥–∏–Ω–∞–º–∏–∫–∏ LTV –∏ ROI\n",
    "    result_in_time, roi_in_time = group_by_dimensions(\n",
    "        result_raw, dimensions + ['dt'], horizon_days\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        result_raw,  # —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "        result_grouped,  # —Ç–∞–±–ª–∏—Ü–∞ LTV\n",
    "        result_in_time,  # —Ç–∞–±–ª–∏—Ü–∞ –¥–∏–Ω–∞–º–∏–∫–∏ LTV\n",
    "        roi_grouped,  # —Ç–∞–±–ª–∏—Ü–∞ ROI\n",
    "        roi_in_time,  # —Ç–∞–±–ª–∏—Ü–∞ –¥–∏–Ω–∞–º–∏–∫–∏ ROI\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5049fd-0d58-44c3-80f2-a1bff84aaa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11edc8-9a52-45b4-860a-15a079a13fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b3b42-b7fe-4ba9-915f-9fc74ceb3055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c538f-35ca-4565-b671-a5a2a9394ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
